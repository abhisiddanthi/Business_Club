<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">
    <meta name="og:image" content="http://bclub.co.in/blog/img/bank.jpg"/>
    <meta property="fb:admins" content="100006371020407"/>
    <meta property="fb:admins" content="100004330893852"/>
<meta name="og:title" content="World bank and its failure" />
<meta name="og:description" content="Have Global Governance Institutions Failed Developing Countries?" />
<meta name="og:url" content="http://bclub.co.in/blog/deep_fake.html" />
<meta property="og:image" content="http://bclub.co.in/blog/img/bank.jpg" />
    <title>DECISION TREES</title>
    <link rel="shortcut icon" href="img/favicon.ico">
<!-- Google analytics code -->
<script>
  (function(i, s, o, g, r, a, m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)}, i[r].l=1*new Date();a=s.createElement(o), 
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a, m)
  })(window, document, 'script', '//www.google-analytics.com/analytics.js', 'ga');

  ga('create', 'UA-65026905-2', 'auto');
  ga('send', 'pageview');

</script>
<!-- Google analytics end-->
    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400, 700, 400italic, 700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic, 400italic, 600italic, 700italic, 800italic, 400, 300, 600, 700, 800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

<style type="text/css">

    #manual td, th{
         padding: 5px;

     }
     #manual td:first-of-type {
        font-weight: bold;
     }

    div.color{
       height:15px;
       width: 15px;
       float: left;
       margin-right: 5px;
    }

    #reference .color{
       height:13px;
       width: 13px;        
    }

    div#moderate{
        background-color: green;

    }
        
    div#significant{
        background-color: yellow;
    }    

    div#severe{
        background-color: red;
    }

    #manual td, th{
        border: 2px solid black;
    }

    #empty{
        border: none;
    }

</style>

</head>

<body>
<!-- Facebook SDK added on 10/7/15 -->
<script>
  window.fbAsyncInit = function() {
    FB.init({
      appId      : '836980526380578', 
      xfbml      : true, 
      version    : 'v2.4'
    });
  };

  (function(d, s, id){
     var js, fjs = d.getElementsByTagName(s)[0];
     if (d.getElementById(id)) {return;}
     js = d.createElement(s); js.id = id;
     js.src = "//connect.facebook.net/en_US/sdk.js";
     fjs.parentNode.insertBefore(js, fjs);
   }(document, 'script', 'facebook-jssdk'));
</script>
<div id="fb-root"></div> <!--Added on 17/08 for like/share -->
<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) return;
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/sdk.js#xfbml=1&version=v2.4&appId=836980526380578";
  fjs.parentNode.insertBefore(js, fjs);F
}(document, 'script', 'facebook-jssdk'));</script><!-- Facebook SDK ends -->


    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top" style="color:black;">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span c lass="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="../../index.html" style="margin-top:-5px;color:white;"><img src="../Analytics/pics/whitelogo.png" style="display:inline; width:36px"> Business Club</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="navbar-nav  navbar-right nav">
                    <li>
                        <a href="../../blog/index.html"> Blogs</a>
                    </li>
                    <li>
                        <a href="../../modules.html">Modules</a>
                    </li>
                    <li>
                        <a href="../../contact/contact.html">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>


    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="margin:0;padding:0;background-image: url('../Analytics/pics/360_F_707027965_o1Nawl8IUYvBowX2BWbJBO8lAyHtkuIa.jpg')">
        <div class="post-heading" align="center" style="padding-top:199px;padding-bottom:50px;">
                            <h1 style="margin-top:125px;color:white;">DECISION TREES</h1>
                            <span class="meta" >Posted by <a href="#">B-Club, IIT Kharagpur</a> on September 19, 2015</span>
                        </div>
        
    </header>

    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1" style="text-align: justify;  text-justify: inter-word;">
                    
                    <p><b>Decision Trees</b></p>
                    <p><b>Motivation:</b></p>
                    <p>Classification techniques for analysts have majorly been Logistic Regression, Decision
                        Trees and SVM. Due to some of the following limitations of Logistic Regression,
                        Decision Trees prove to be very useful:
                        </p>
                    <ol>
                        <li>Doesn’t perform well when the feature space is too large</li>
                        <li>Doesn’t handle large number of variables/features well</li>
                        <li>Linear decision boundary layers</li>
                    </ol>
                    <p><b>Tree</b></p>

                    <p><b>What are decision trees?</b></p>

                    <p>Decision trees are a powerful prediction method and extremely popular.
                        They are popular because the final model is so easy to understand by practitioners and
                        domain experts alike. The final decision tree can explain exactly why a specific
                        prediction was made, making it very attractive for operational use</p>

                    
                    <p><b>Representation</b></p>
                    <p>Given below is an example of a decision tree classifying whether a day is suitable for
                        playing tennis .</p>
            
                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.10.11.png" width="100%"/></p>

                    <p>A decision tree consist of three main parts - root nodes , leaf nodes , branches .It
                        starts with a single node called “root node ” which then branches into “child nodes” .
                        At each node , a specific attribute is tested and the training data is classified
                        accordingly.
                        </p>
                    <p>
                        In the above example , the root node tests the attribute “Outlook” and splits into 3
                        branches according to the 3 values taken by the attribute - “Sunny” , “Overcast ”and
                        “Rain” .
                        </p>
                    
                    <p><b>Regression vs Classification </b></p>

                    <p>Classification trees are used when the target variable is categorical in nature whereas
                        Regression trees are used when the target variable is continuous or numerical in
                        nature
                        </p>
                        <p>In case of linear regression , a single formula is used for prediction in the entire training
                        data set. But if the number of features are more , they can interact in non-linear ways
                        and modelling a single formula becomes difficult .Hence regression trees are used. 
					</p>


                
                    <p>A regression tree is built through a process known as binary recursive partitioning, in
                        which the dataset in partitioned into smaller regions until we obtain data sets where we
                        can fit simpler models.</p>
                        
                    <p>Classification trees works in the same manner, only the predictor variables are
                        categorical in nature.
                        </p>

                 <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.14.10.png" width="100%"/></p>


                    <p><b>Building a Model:</b></p>

                    <p>Choosing a split criteria to to start forming child nodes is the first step in a building our
                        decision trees. There are many index or measures available to test the homogeneity of
                        a sample after a split, some of the popular ones are mentioned below</p>

                        <p><b>Popular cost functions :</b></p>
                    <p><b>1. Information gain :</b></p>

                    <p>Information gain measures the reduction in entropy caused by classifying the training
                        data on the basis of an attribute. Higher the information gain ,better is the attribute in
                        classifying the data.</p>
                    <p>Mathematically, </p>

                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.17.08.png" width="100%"/></p>

                    <p><b>2. Gini Index :</b></p>

                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.17.18.png" width="100%"/></p>

                    <p><b>3. Chi - square test :</b></p>

                    <p>Chi-square is another test used to determine the statistical
                        significance between the parent node and the child-nodes after the split. </p>

                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.19.32.png" width="100%"/></p>

                    <p><b>Evaluating the performance of Decision trees :</b></p>

                    <p>Confusion Matrix : The performance of the decision tree over the test data set can be
                        summarised in a confusion matrix.
                        <br>The each training example will fall into one of the four categories -</p>
                    <ol>
                        <li>True Positives (TP) : All positive instances correctly classified</li>
                        <li>False Positives (FP) : All negative instances incorrectly classified as positive.</li>
                        <li>False Negatives (FN) : All positive instances incorrectly classified as negative</li>
                        <li>True Negatives (TN) : All negative instances correctly classified</li>
                    </ol>

                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.23.26.png" width="100%"/></p>

                    <p>Accuracy can be calculated from the table as the ratio of correct predictions to total
                        predictions .
                        <br><br>
                        However, calculating accuracy alone is not very reliable if the number of datasets belong
                        to each class are very different .
                        <br><br>Decision trees are prone to overfitting . If they are grown too deep , they lose
                        generalisation capability .</p>
                        
                        <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.25.03.png" width="100%"/></p>

                    <p><b>Tree pruning :</b></p>
                    
                    <p>Pruning is a general technique to avoid overfitting by elimination the branches of the
                        tree that provide little power to classify data .</p>

                        <p>Some of the popular pruning strategies are :</p>
                    
                    <ol>
                        <li>Cost Complexity pruning : A series of pruned trees are generated by removing a
                            sub-tree and replacing it with a leaf node . The optimally pruned tree among
                            these is the one with the least cross-validated error .</li>

                            <li>Reduced error pruning : In this method , a sub-tree is replaced by a leaf-node
                                and if the prediction accuracy is not affected significantly , the changes are kept .</li>


                    </ol>

                    <p><b>Random forests :</b></p>

                    <p>As discussed earlier , when working with large sets of data decision trees often run into
                        the problem of overfitting. Hence, an ensemble learning technique called Random
                        Forests is used.
                        <br><br>

                        Ensemble Learning refers to using multiple learning multiple learning algorithms to
                        make better predictive models. Some of the common ensemble learning types is
                        bagging, boosting, bayesian parameter average etc.
                        <br><br>
                        As the name suggests random “forest” is a combination of large number of decision
                        “trees”. A random forest grows multiple trees.
                        <br><br>
                        To classify a new object based on attributes, each tree gives a classification which is
                        then aggregated into one result .The forest chooses the classification by the number of
                        votes from all the trees and in case of regression, it takes the average of outputs by
                        different trees.</p>

                        <p>Random forests are considered more popular than single decision tree due to the fact
                            that they can minimise overfitting without bringing in much error of bias .
                            <br><br>
                            Despite being more accurate , the random forest algorithms are computationally
                            expensive and hard to implement .</p>

                        <p><b>Implementation</b></p>

                        <p>We’ll break down our implementation on the banknote case study into the following for
                            steps:</p>

                        <ol>
                            <li>Data Exploring and Pre-processing</li>
                            <li>Data Splitting</li>
                            <li>Building Model</li>
                            <li>Making Predictions</li>
                        </ol>

                        <p><b>Data Exploring and Pre-processing:</b></p>

                        <p>This is how a snapshot of our data looks like:</p>

                    <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.37.29.png" width="100%"/></p>

                    <p>To give a brief background of the data and the column headers:
                        <br><br>
                        Data was extracted from images that were taken from genuine and forged banknote-like
                        specimens. For digitization, an industrial camera usually used for print inspection was
                        used. The final images have 400 x 400 pixels. Due to the object lens and distance to the
                        investigated object grayscale pictures with a resolution of about 660 dpi were gained.
                        Wavelet Transform tool were used to extract features from images.</p>
                    
                        <p>The variables and their respective denotion goes as follows:</p>

                        <ul>
                            <li> Var: variance of Wavelet Transformed image (continuous) </li>
                            <li>Skewness: skewness of Wavelet Transformed image (continuous) </li>
                            <li>Kurtosis: kurtosis of Wavelet Transformed image (continuous) </li>
                            <li>Entropy: Entropy of image(continuous)</li>
                            <li>Class:  DIscrete variable accounting for the class in which the banknote lies </li>
                        </ul>

                        <p>The is taken from the UCI Repository:
                            <br>
                            http://archive.ics.uci.edu/ml/datasets/banknote+authentication
                            <br>
                            The data has no null values and any other cleaning are also not needed, only column
                            headers need to be added and converting the txt file to csv with a comma delimiter is
                            needed. The implementation for the same is:</p>

                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.40.17.png" width="100%"/></p>

                            <p>For data exploration we start with multivariate analysis to get an idea of how the
                                decision boundary might look like</p>

                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.40.53.png" width="100%"/></p>

                                <p>A little idea about the decision boundary can be gathered from the above visualization,
                                    where the Red dots represent class 0 and blue represent class 1. </p>

                            <p><b>Building the Model:</b></p>

                            <p>We’ll be using two splitting techniques and then compare the better model. In each case
                                we would need to split the data into train and test set, done as below: (As of now we
                                have limited the maximum tree depth, we would discuss the reasoning behind later)</p>

                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.42.35.png" width="100%"/></p>
                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.42.59.png" width="100%"/></p>
                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.43.06.png" width="100%"/></p>


                            <p><b>Performance of the Model</b></p>

                            <p>Sklearn has a module for accuracy metrics, we would fit both the models and check their
                                accuracy:</p>

                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.47.25.png" width="100%"/></p>
                            <p><b>Random Forests </b></p>
                            <p style="text-align: center;"><img src="../Analytics/pics/Screenshot 2024-11-06 at 12.47.37.png" width="100%"/></p>
                                <p>As you can see the accuracy of both the models have improved significantly.
                                    <br><br>
                                    A new dimension to the study of Decision Trees comes after learning about bagging and
                                    boosting. These topics have been covered in advanced modules</p>

                    <!-- sample comment -->
                    <div class="fb-comments" data-href="http://bclub.co.in/blog/deep_fake.html" data-numposts="5" width=750></div>
                    <!-- sample comment ends -->
                    <div class="fb-like" data-href="http://bclub.co.in/blog/deep_fake.html" data-layout="standard" data-action="like" data-show-faces="false" data-share="true" width="100%"></div>
                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://www.facebook.com/bclubkgp" target="_blank">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-facebook fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="#">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted"><img src="img/clublogo.jpg">  Copyright &copy; Business Club, IIT Kharagpur</p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>
    <img alt="Have Global Governance Institutions Failed Developing Countries?" rel="Facebook image" src="http://bclub.co.in/blog/img/bank.jpg" style="display: none;">  
</body>

</html>
